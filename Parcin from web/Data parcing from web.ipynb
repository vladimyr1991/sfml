{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import parser\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'url=\\'../My_data_science/Book1.xls\\'\\ndata = pd.read_excel(url,sheet_name = \\'Sheet1\\')\\ndf = data[\\'Data\\'].astype(str)\\nnew_df =[]\\nfor art in df:\\n    if len(art)<8:\\n        art = \"00\" + art\\n        new_df.append(art)\\n    else:\\n        new_df.append(art)\\nnew_df = new_df'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new_df = ['10205614','90385767', '80385763', '50385750', '60385764', '20385761', '60385759', '80385744','80385758', '10385766', '00385757', '10385752', '30385765', '70385754', '90385753', '40385755', '70385749']\n",
    "url='../My_data_science/Book1.xls'\n",
    "data = pd.read_excel(url,sheet_name = 'Sheet1')\n",
    "df = data['Data'].astype(str)\n",
    "new_df =[]\n",
    "# If lenght of article (from excell file) is less then 8 symbols - add two zeroes to article\n",
    "for art in df:\n",
    "    if len(art)<8:\n",
    "        art = \"00\" + art\n",
    "        new_df.append(art)\n",
    "    else:\n",
    "        new_df.append(art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create lists for data collection from web pages\n",
    "\n",
    "Article_num = []\n",
    "Article_family = []\n",
    "Article_part = []\n",
    "Article_size = []\n",
    "Article_color = []\n",
    "Article_quantity1 = []\n",
    "Article_quantity = []\n",
    "Article_product_area = []\n",
    "\n",
    "#Iterate and parce through necessary data on web page\n",
    "\n",
    "\n",
    "for item in new_df:\n",
    "    # Here Item is number of article, and necessary web page is changing by changing item_no in hyperlink\n",
    "    url = 'http://iwww.pia-facts.ikea.com/Pages/PIAFacts.aspx?item_no='+item+'&lang_code=gb&cty_code=OF&ParentItem=&ItemAdd=0'\n",
    "    html = requests.get(url).content\n",
    "    df_list = pd.read_html(html)\n",
    "    df_head = df_list[2]\n",
    "    df_tail = df_list[-13]\n",
    "    \n",
    "    #Creating lists of parced data and imputing specific data there\n",
    "    Article_num.append(item)\n",
    "    Article_family.append(df_head[0][0])\n",
    "    Article_part.append(df_head[1][0])\n",
    "    Article_size.append(df_head[2][0])\n",
    "    Article_color.append(df_head[4][0])\n",
    "    Article_quantity.append(df_head[5][0])\n",
    "    #Some pages have issues with making, so some of them located in other locations\n",
    "    try:\n",
    "        Article_product_area.append(df_tail[1][2])\n",
    "    except:\n",
    "        Article_product_area.append(df_list[-14][1][2])\n",
    "            \n",
    "Article_size = list(map(lambda x: x[2:],Article_size))\n",
    "Article_color = list(map(lambda x: x[2:],Article_color))\n",
    "Article_part = list(map(lambda x: x[2:],Article_part))\n",
    "#Some articles, in terms of quantity will have no data, because product have only 1 pack, that's why I put string \"1 pack\" if nan\n",
    "Np_q = np.array(Article_quantity)\n",
    "for x in Np_q:\n",
    "    if x != 'nan':\n",
    "        Article_quantity1.append(x[2:])\n",
    "    else:\n",
    "        Article_quantity1.append('1 pack') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dict and put inside all parced data\n",
    "dict_table = {'Article_num':Article_num,'Article_family':Article_family,'Article_part':Article_part,'Size':Article_size,'Color':Article_color,'Quantity':Article_quantity1,'Product_area':Article_product_area}\n",
    "df = pd.DataFrame(dict_table)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('output.xlsx')\n",
    "df.to_excel(writer,'Sheet1',index = False)\n",
    "writer.save()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
